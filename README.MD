# ETL —  Extract, Transform, Load.

## Урок 1. Модели данных и нормализация таблиц. Схема «звезда»

1. Условия ДЗ написаны на слайде 44 s1.pdf. Если не получиться, то просто запустите скрипт s1.scala, скоректируйте пути. В рамках первого семинара вы установили инструментарий ETL.
2. Нарисуйте архитектуру ETL процесса для сбора и анализа данных компанией которая хочет провести маркетинговую кампанию, используя app.diagrams.net. Сделайте описание почему вы считаете что архитектура должна выглядеть именно так.
3. Постройте реляционную и иерархическую модели данных для магазина который продает телефоны.
4. Определите в какой нормальной форме данная таблица, приведите ее ко 2 и 3 нормальным формам последовательно.
Нужно в apache spark создать таблицу  сданными ниже. Можно импортировать из Excel либо с генерировать ее кодом.

Сделать нормализацию по образцу 
(например, как здесь https://ru.wikipedia.org/wiki/%D0%92%D1%82%D0%BE%D1%80%D0%B0%D1%8F_%D0%BD%D0%BE%D1%80%D0%BC%D0%B0%D0%BB%D1%8C%D0%BD%D0%B0%D1%8F_%D1%84%D0%BE%D1%80%D0%BC%D0%B0)
 
Сохранить полученный результат в БД. На проверку соберите код, скриншоты отработки консоли спарка и полученный результат в БД в один pdf файл.

Employee_ID    Name       Job_Code    Job         City_code   Home_city
E001           Alice      J01         Chef        26          Moscow
E001           Alice      J02         Waiter      26          Moscow
E002           Bob        J02         Waiter      56          Perm
E002           Bob        J03         Bartender   56          Perm
E003           Alice      J01         Chef        56          Perm

## Урок 2. Введение в подготовку данных для аналитиков. Таблицы фактов и таблицы измерений

1. Скачайте датасет fifаs2.сsv. Проанализируйте его и определите, какие данные являются неполными. Удалите
ненужные колонки и недостающие значения.

2. Найдите в датафрейме полные дубликаты и удалите их. Значения могут быть одинаковыми, но написаны по-разному. Например, может отличаться размер регистра (заглавные и строчные буквы). Особое внимание уделить колонке с названиями команд.

3. Напишите функцию, которая добавит колонку с разбиением возраста по группам: до 20, от 20 до 30, от 30 до
36 и старше 36. Посчитайте количество футболистов в каждой категории.
ЗАДАНИЕ НУЖНО СДЕЛАТЬ С ПОМОЧЬЮ APACHE SPARK КАК ПОКАЗАНО НА СЕМИНАРЕ. 
Соберите все в один pdf, код и скриншоты записанных таблиц с данными, скриншоты отработки лога спарка.

## Урок 3. Получение денормализованных таблиц из нормализованных

1. Денормализуйте таблицу так, чтобы не нужно было для каждого рекламодателя постоянно подсчитывать количество кампаний и продаж.

2. В базе данных есть две таблицы: страны и клиенты. Одной из потребностей компании является исследование клиентов и стран с точки зрения эффективности продаж, поэтому часто выполняются объединения между таблицами: клиенты и страны. Что нужно сделать, чтобы ограничить частое объединение этих двух таблиц?

3. Вернемся к первому примеру. Предположим, компания хочет регулярно извлекать данные о продажах, например, о кампаниях или рекламодателях с полными именами. Как мы можем решить проблему постоянной необходимости объединения таблиц?

4. Из задания которое разбирали на семинаре взять запрос и использовать его в скаловском скрипте, через спарк создать вторую таблицу. 
И сделать через GROUP_CONCAT список как на семинаре, Сделайте формат времени 11.01.23 22.29 (без секунд) и через case сократите названия статусов 
(Например, Зарегистрирован З, Закрыт --> ЗТ).

5.  Всю туже саму логику запроса перенести на спарк.

## Урок 4. Партицирование данных по дате. Динамическое партицирование

1. За основу возьмите Задание 4 решенное на семинаре.
В файле s4_2 параметры кредита: Займ 9400000, срок 30 лет, ставка 10.6%.
Через https://calcus.ru/kreditnyj-kalkulyator-s-dosrochnym-pogasheniem добавьте два листа в Excel с постоянным платежом 120 или 150 тыс. руб.
(Необязательно, но можете также сделать и для платежа 250 и 300).
Добавьте графики с досрочным погашением по этим пирометрам. Т.е. линии по выплатам основного долга и процентов если платеж будет 120 или 150 тыс. руб. В результате должно получиться 6 линий. Используйте разные цвета.

### Урок 5. Обзор возможностей Airflow, установка и настройка

1. Установите AirFlow как показано на семинаре, соберите список команд установки, скриншоты GUI и работы AirFlow из мобы. Соберите все данные в один pdf файл.
2. Проверить гипотезу будет ли достаточно установки sudo apt install -y python3 python3-pip python3-venv без sudo apt install python3.8 
3. Создайте мануал со списком команд для установки.

### Урок 6. Операторы в Airflow и их применение для ETL

1. Установить спарк как показано на семинаре:
    - Для этого переместите папку spark в home. 
    - Дайте права командой chmod -R 777 ./
    - nano ~/.bashrc
    - export SPARK_HOME=/home/spark && export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin
    - source ~/.bashrc
    - sudo apt-get install openjdk-8-jdkpip
    - Указанные библиотеки нужно также установить и в виртуальную среду: python3 -m venv airflow venv && source airflow venv /bin/activate
    - pip install pyspark==3.2.4
    - pip install pandas==1.5.3
    - pip install SQLAlchemy==1.4.46
    Используйте ДЗ которые вы мне высылали для 3-4 семинара. Запустите данные задачи ПОСЛЕДОВАТЕЛЬНО, одну за другой в аирфлоу. Пришлите мне скриншоты выполненных задач в аирфлоу, логов аирфлоу, скриншоты что у вас записались таблицы в БД mysql на WSL. По возможности доработайте код чтобы изображение с линии платежей генерировалось в указанную директорию. Скриншоты соберите в pdf.

### Урок 7. Построение пайплайнов и визуализация потоков данных в Airflow

1. Ваша задача с использование пандас, записать полученную температуру в таблицу mysql. Таблица должна содержать как минимум текущее время и температуру (т.е. два поля). Таблицу не удаляем, используем append.
2. То что мы делали на четвертом семинаре (ДЗ4) задача с гарфиком. Нужно с помощью аирфлоу (PythonOperator) сохранить этот график в png/jpeg. Используйте пандас, считайте им таблицу из mysql, постройте график и сохраните его в указанную директорию. На проверку ДЗ высылайте код и скриншоты аирфлоу выполненных задач, логов и сохраненного файла (в pdf).

3. Зарегистрируйтесь в ОрепWeatherApi (https://openweathermap.org/api)
   3.1 Создайте ETL, который получает температуру в заданной вами локации, и дальше делает ветвление:
    - В случае, если температура больше 15 градусов цельсия — идёт на ветку, в которой есть оператор, выводящий на экран «тепло»;
    - В случае, если температура ниже 15 градусов, идёт на ветку с оператором, который выводит в консоль «холодно».
    - Оператор ветвления должен выводить в консоль полученную от АРI температуру.
    - Приложите скриншот графа и логов работы оператора ветвленния.
 
### Урок 8. Специфика применения ETL в различных предметных сферах

1. Используя материалы семинара и s8dag.py нужно доработать задачу в части записи данных в mysq по погоде яндекса и open weather (поля - метка текущего времени и температура). 
    - pip install apache-airflow-providers-telegram - команда для установки модуля Telegram
2. Создать еще одну задачу по отправке данных в телеграм. За основу взять данные таблиц платежей из 4-го семинара (все 360 периодов), конвертировать их в текстовый формат и отправить их в telegram. 
3. Рассмотрите возможность применения разметки html либо markdown. Нужно выслать одну основную таблицу. Есть есть лимит по сообщениям, можно ограничить количество строк таблицы. Можете использовать функцию limit в sql запросе.
4. К ДЗ приложите код и скриншоты отрабоданных задач аирфлоу, а также отправленный слепкок из базы данных в вашем чаботе. 
